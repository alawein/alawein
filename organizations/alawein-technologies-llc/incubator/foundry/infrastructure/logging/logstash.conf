input {
  # Collect logs from Docker containers via syslog
  syslog {
    port => 5514
    type => "docker"
  }

  # Collect application logs via TCP
  tcp {
    port => 5000
    codec => json_lines
    type => "application"
  }

  # Collect Nginx access logs
  file {
    path => "/var/log/nginx/access.log"
    start_position => "beginning"
    type => "nginx-access"
  }

  # Collect Nginx error logs
  file {
    path => "/var/log/nginx/error.log"
    start_position => "beginning"
    type => "nginx-error"
  }

  # Collect PostgreSQL logs
  file {
    path => "/var/log/postgresql/*.log"
    start_position => "beginning"
    type => "postgresql"
  }

  # Collect Redis logs
  file {
    path => "/var/log/redis/*.log"
    start_position => "beginning"
    type => "redis"
  }

  # Heartbeat for monitoring
  heartbeat {
    interval => 60
    type => "heartbeat"
  }
}

filter {
  # Parse Docker logs
  if [type] == "docker" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}"
      }
      overwrite => ["message"]
    }
  }

  # Parse Nginx access logs
  if [type] == "nginx-access" {
    grok {
      match => {
        "message" => '%{IPORHOST:remote_addr} - %{DATA:remote_user} \[%{HTTPDATE:time_local}\] "%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:http_version}" %{NUMBER:status} %{NUMBER:bytes_sent} "%{DATA:http_referer}" "%{DATA:user_agent}" "%{DATA:http_x_forwarded_for}" rt=%{NUMBER:request_time} uct="%{DATA:upstream_connect_time}" uht="%{DATA:upstream_header_time}" urt="%{DATA:upstream_response_time}"'
      }
    }

    mutate {
      convert => {
        "status" => "integer"
        "bytes_sent" => "integer"
        "request_time" => "float"
      }
    }

    geoip {
      source => "remote_addr"
      target => "geoip"
    }

    useragent {
      source => "user_agent"
      target => "useragent"
    }
  }

  # Parse Nginx error logs
  if [type] == "nginx-error" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{POSINT:pid}#%{POSINT:thread_id}: %{GREEDYDATA:message}"
      }
      overwrite => ["message"]
    }
  }

  # Parse PostgreSQL logs
  if [type] == "postgresql" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:timezone} \[%{NUMBER:pid}\] %{WORD:user}@%{WORD:database} %{LOGLEVEL:level}: %{GREEDYDATA:query}"
      }
    }

    if [query] =~ /^(SELECT|INSERT|UPDATE|DELETE|CREATE|DROP|ALTER)/ {
      mutate {
        add_field => { "query_type" => "%{WORD:query_type}" }
      }
    }
  }

  # Parse application JSON logs
  if [type] == "application" {
    json {
      source => "message"
    }

    # Extract trace ID for distributed tracing
    if [trace_id] {
      mutate {
        add_field => { "[@metadata][trace_id]" => "%{trace_id}" }
      }
    }
  }

  # Add common fields
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:production}"
      "project" => "crazyideas"
    }
  }

  # Parse user agent for all logs with user_agent field
  if [user_agent] {
    useragent {
      source => "user_agent"
      target => "useragent"
    }
  }

  # Parse timestamps
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "MMM dd HH:mm:ss" ]
    target => "@timestamp"
  }

  # Add performance metrics
  if [request_time] {
    ruby {
      code => "
        request_time = event.get('request_time').to_f
        if request_time > 5
          event.set('performance_category', 'slow')
        elsif request_time > 1
          event.set('performance_category', 'moderate')
        else
          event.set('performance_category', 'fast')
        end
      "
    }
  }

  # Detect errors and anomalies
  if [level] =~ /(?i)(error|critical|fatal|emergency)/ or [status] >= 500 {
    mutate {
      add_tag => [ "error", "alert" ]
      add_field => { "alert_priority" => "high" }
    }
  } elsif [level] =~ /(?i)(warning|warn)/ or [status] >= 400 {
    mutate {
      add_tag => [ "warning" ]
      add_field => { "alert_priority" => "medium" }
    }
  }

  # Security monitoring
  if [request] {
    # Detect SQL injection attempts
    if [request] =~ /(?i)(union|select|insert|update|delete|drop|create|alter|exec|execute|script|javascript|alert|prompt|confirm)/ {
      mutate {
        add_tag => [ "security", "potential_sql_injection" ]
        add_field => { "security_threat" => "sql_injection_attempt" }
      }
    }

    # Detect XSS attempts
    if [request] =~ /(<script|javascript:|onerror=|onload=|alert\(|prompt\(|confirm\()/ {
      mutate {
        add_tag => [ "security", "potential_xss" ]
        add_field => { "security_threat" => "xss_attempt" }
      }
    }

    # Detect path traversal attempts
    if [request] =~ /(\.\.|\/\.\.|\.\.\/|%2e%2e|%252e%252e)/ {
      mutate {
        add_tag => [ "security", "potential_path_traversal" ]
        add_field => { "security_threat" => "path_traversal_attempt" }
      }
    }
  }

  # Rate limiting detection
  if [type] == "nginx-access" {
    throttle {
      before_count => 100
      after_count => 100
      period => 60
      max_age => 120
      key => "%{remote_addr}"
      add_tag => "rate_limit_exceeded"
    }
  }

  # Remove sensitive data
  mutate {
    remove_field => [ "password", "token", "secret", "api_key", "authorization" ]
  }

  # Calculate response time percentiles
  if [request_time] {
    aggregate {
      task_id => "%{host}-%{request}"
      code => "
        map['response_times'] ||= []
        map['response_times'] << event.get('request_time')
        if map['response_times'].length >= 100
          sorted = map['response_times'].sort
          event.set('p50', sorted[49])
          event.set('p95', sorted[94])
          event.set('p99', sorted[98])
          map['response_times'] = []
        end
      "
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "crazyideas-%{type}-%{+YYYY.MM.dd}"
    template_name => "crazyideas"
    template => "/etc/logstash/templates/elasticsearch-template.json"
    template_overwrite => true
  }

  # Send errors to separate index for alerting
  if "error" in [tags] or "security" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "crazyideas-alerts-%{+YYYY.MM.dd}"
    }
  }

  # Send metrics to InfluxDB for time-series analysis
  if [type] == "metrics" {
    influxdb {
      host => "influxdb"
      port => 8086
      db => "crazyideas_metrics"
      measurement => "%{measurement}"
      data_points => {
        "value" => "%{value}"
        "host" => "%{host}"
        "app" => "%{app}"
      }
    }
  }

  # Send critical alerts to PagerDuty
  if [alert_priority] == "high" {
    pagerduty {
      service_key => "${PAGERDUTY_SERVICE_KEY}"
      details => {
        "timestamp" => "%{@timestamp}"
        "host" => "%{host}"
        "message" => "%{message}"
        "level" => "%{level}"
      }
    }
  }

  # Send to stdout for debugging (remove in production)
  stdout {
    codec => rubydebug
  }
}