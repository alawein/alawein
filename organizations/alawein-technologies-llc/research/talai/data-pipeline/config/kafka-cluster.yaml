apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: talai-kafka-cluster
  namespace: data-pipeline
spec:
  kafka:
    version: 3.6.1
    replicas: 5
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
        authentication:
          type: scram-sha-512
      - name: tls
        port: 9093
        type: internal
        tls: true
        authentication:
          type: tls
      - name: external
        port: 9094
        type: loadbalancer
        tls: true
        authentication:
          type: scram-sha-512
        configuration:
          bootstrap:
            loadBalancerIP: 10.0.0.100
          brokers:
            - broker: 0
              loadBalancerIP: 10.0.0.101
            - broker: 1
              loadBalancerIP: 10.0.0.102
            - broker: 2
              loadBalancerIP: 10.0.0.103
            - broker: 3
              loadBalancerIP: 10.0.0.104
            - broker: 4
              loadBalancerIP: 10.0.0.105
    config:
      # Performance optimization
      num.network.threads: 8
      num.io.threads: 16
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      num.partitions: 12
      default.replication.factor: 3
      min.insync.replicas: 2

      # Log configuration
      log.retention.hours: 168  # 7 days
      log.segment.bytes: 1073741824  # 1GB
      log.retention.check.interval.ms: 300000
      compression.type: snappy

      # Transaction support
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2

      # Performance tuning
      replica.fetch.max.bytes: 10485760
      group.initial.rebalance.delay.ms: 3000
      offsets.topic.replication.factor: 3

    storage:
      type: persistent-claim
      size: 500Gi
      class: ssd-regional
      deleteClaim: false

    rack:
      topologyKey: topology.kubernetes.io/zone

    resources:
      requests:
        memory: 16Gi
        cpu: 4000m
      limits:
        memory: 32Gi
        cpu: 8000m

    jvmOptions:
      -Xms: 12G
      -Xmx: 12G
      -XX:
        UseG1GC: true
        MaxGCPauseMillis: 20
        InitiatingHeapOccupancyPercent: 35
        G1HeapRegionSize: 16M
        MinMetaspaceFreeRatio: 50
        MaxMetaspaceFreeRatio: 80

    metricsConfig:
      type: jmxPrometheusExporter
      valueFrom:
        configMapKeyRef:
          name: kafka-metrics
          key: kafka-metrics-config.yml

  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 100Gi
      class: ssd-regional
    resources:
      requests:
        memory: 4Gi
        cpu: 1000m
      limits:
        memory: 8Gi
        cpu: 2000m
    jvmOptions:
      -Xms: 2G
      -Xmx: 2G

  entityOperator:
    topicOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: 500m
        limits:
          memory: 1Gi
          cpu: 1000m
    userOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: 500m
        limits:
          memory: 1Gi
          cpu: 1000m

  kafkaExporter:
    topicRegex: ".*"
    groupRegex: ".*"
    resources:
      requests:
        memory: 128Mi
        cpu: 200m
      limits:
        memory: 256Mi
        cpu: 500m

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: talai-research-events
  namespace: data-pipeline
  labels:
    strimzi.io/cluster: talai-kafka-cluster
spec:
  partitions: 24
  replicas: 3
  config:
    retention.ms: 604800000  # 7 days
    segment.bytes: 1073741824
    compression.type: snappy
    max.message.bytes: 10485760  # 10MB
    min.insync.replicas: 2

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: talai-agent-commands
  namespace: data-pipeline
spec:
  partitions: 12
  replicas: 3
  config:
    retention.ms: 86400000  # 1 day
    compression.type: lz4
    cleanup.policy: delete

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: talai-metrics-stream
  namespace: data-pipeline
spec:
  partitions: 36
  replicas: 3
  config:
    retention.ms: 259200000  # 3 days
    compression.type: snappy
    cleanup.policy: compact

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnect
metadata:
  name: talai-connect-cluster
  namespace: data-pipeline
spec:
  version: 3.6.1
  replicas: 3
  bootstrapServers: talai-kafka-cluster-kafka-bootstrap:9093
  tls:
    trustedCertificates:
      - secretName: talai-cluster-ca-cert
        certificate: ca.crt
  config:
    group.id: connect-cluster
    offset.storage.topic: connect-cluster-offsets
    config.storage.topic: connect-cluster-configs
    status.storage.topic: connect-cluster-status
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3

    # Connector configurations
    connector.client.config.override.policy: All
    consumer.max.poll.records: 500
    consumer.max.poll.interval.ms: 300000

  build:
    output:
      type: docker
      image: talai/kafka-connect:latest
      pushSecret: docker-registry-secret
    plugins:
      - name: debezium-postgres
        artifacts:
          - type: tgz
            url: https://repo1.maven.org/maven2/io/debezium/debezium-connector-postgres/2.4.0.Final/debezium-connector-postgres-2.4.0.Final-plugin.tar.gz
      - name: elasticsearch-sink
        artifacts:
          - type: zip
            url: https://github.com/confluentinc/kafka-connect-elasticsearch/releases/download/v14.0.6/confluentinc-kafka-connect-elasticsearch-14.0.6.zip
      - name: s3-sink
        artifacts:
          - type: zip
            url: https://github.com/confluentinc/kafka-connect-storage-cloud/releases/download/v10.5.0/confluentinc-kafka-connect-s3-10.5.0.zip

  resources:
    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      memory: 4Gi
      cpu: 2000m

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-metrics
  namespace: data-pipeline
data:
  kafka-metrics-config.yml: |
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    rules:
      # Kafka server metrics
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          broker: "$4:$5"
      - pattern: kafka.server<type=(.+), name=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE

      # Kafka network metrics
      - pattern: kafka.network<type=(.+), name=(.+)><>Value
        name: kafka_network_$1_$2
        type: GAUGE

      # Kafka controller metrics
      - pattern: kafka.controller<type=(.+), name=(.+)><>Value
        name: kafka_controller_$1_$2
        type: GAUGE

      # Kafka log metrics
      - pattern: kafka.log<type=(.+), name=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_log_$1_$2
        type: GAUGE
        labels:
          topic: "$3"
          partition: "$4"