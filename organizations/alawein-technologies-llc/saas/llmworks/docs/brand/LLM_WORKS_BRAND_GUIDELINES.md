# LLM Works Brand Guidelines

## Brand Identity

### Name & Tagline
- **Primary Name**: LLM Works
- **Tagline**: "Evaluate LLMs with confidence"
- **Full Description**: Open-source LLM evaluation platform with interactive testing and rigorous benchmarking

### Logo Specifications
- **Primary Mark**: "LLM Works" wordmark in Inter Display Bold
- **Icon**: Analytical prism (geometric, minimal)
- **Minimum Sizes**: 
  - Horizontal: 24px height
  - Stacked: 20px height
  - Icon-only: 16px minimum

### Color Palette

#### Primary Colors (HSL)
```css
/* Analytical Blue */
--primary: 214 84% 56%;
--primary-foreground: 210 40% 98%;
--primary-muted: 214 84% 46%;

/* Workshop Gray */
--secondary: 215 16% 47%;
--secondary-foreground: 215 16% 97%;

/* Insight Orange */
--accent: 25 95% 53%;
--accent-foreground: 26 83% 14%;
```

#### Usage Guidelines
- **Primary Blue**: Main actions, primary CTAs, brand elements
- **Orange Accent**: Highlights, alerts, secondary actions
- **Gray**: Text, borders, subtle backgrounds

### Typography
- **Primary Font**: Inter (400, 500, 600, 700)
- **Monospace**: JetBrains Mono (code, technical content)
- **Hierarchy**: Consistent scale from 12px to 36px

## Voice & Tone

### Brand Personality
- **Evidence-first**: Data-driven, transparent, verifiable
- **Human-centered**: Accessible, clear, empowering
- **Professional**: Credible, trustworthy, systematic
- **Open**: Collaborative, transparent, community-driven

### Writing Guidelines
- Use active voice and clear, direct language
- Focus on benefits and outcomes, not just features
- Emphasize transparency, auditability, and trust
- Avoid overly technical jargon in user-facing content

## Product Naming

### Core Platform
- **LLM Works** - Main platform name
- **The Arena** - Interactive testing environment
- **The Bench** - Benchmarking suite

### Framework Components
- **Arbiter** - Evaluation protocol framework
- **Verifier** - Audit trail and proof system
- **Dynamic Elo** - Performance ranking system

## Usage Examples

### Headlines
✅ "Evaluate LLMs with confidence"
✅ "Auditable AI evaluation made simple"
✅ "Trust through transparent testing"

### Descriptions
✅ "Open-source LLM evaluation platform with auditable results"
✅ "Unite interactive testing and rigorous benchmarking"
✅ "Verifiable evaluation protocols for professional teams"

### Call-to-Actions
✅ "Try in Browser"
✅ "View Benchmarks"  
✅ "Browse Examples"

## Implementation Notes

### File Naming
- Use `llmworks` for technical identifiers
- Use "LLM Works" for display names
- Export files: `llmworks-export-{timestamp}.json`

### Domain & URLs
- Primary: llmworks.dev
- Social: @llmworks
- Repository: github.com/llmworks (planned)

### Legal
- Trademark: LLM Works® (pending)
- Copyright: LLM Works Community
- License: MIT

---
*Last Updated: January 2025*
*Version: 1.0*