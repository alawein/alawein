import { useState, useCallback } from 'react';
import type { ModelData } from '@/components/comparison/ModelComparisonDashboard';

// Mock model data - in production this would come from API/database
const MOCK_MODELS: ModelData[] = [
  {
    id: 'gpt-4o',
    name: 'GPT-4o',
    provider: 'OpenAI',
    metrics: { accuracy: 92, speed: 85, cost: 65, reasoning: 94, creativity: 88, safety: 90 },
    latency: 450,
    costPer1kTokens: 0.015,
    contextWindow: 128000,
  },
  {
    id: 'claude-3-sonnet',
    name: 'Claude 3.5 Sonnet',
    provider: 'Anthropic',
    metrics: { accuracy: 90, speed: 88, cost: 70, reasoning: 92, creativity: 91, safety: 95 },
    latency: 380,
    costPer1kTokens: 0.012,
    contextWindow: 200000,
  },
  {
    id: 'claude-3-opus',
    name: 'Claude 3 Opus',
    provider: 'Anthropic',
    metrics: { accuracy: 94, speed: 75, cost: 40, reasoning: 96, creativity: 93, safety: 96 },
    latency: 650,
    costPer1kTokens: 0.075,
    contextWindow: 200000,
  },
  {
    id: 'gemini-pro',
    name: 'Gemini 1.5 Pro',
    provider: 'Google',
    metrics: { accuracy: 88, speed: 90, cost: 75, reasoning: 87, creativity: 82, safety: 88 },
    latency: 320,
    costPer1kTokens: 0.0035,
    contextWindow: 1000000,
  },
  {
    id: 'gemini-flash',
    name: 'Gemini 2.0 Flash',
    provider: 'Google',
    metrics: { accuracy: 85, speed: 95, cost: 90, reasoning: 82, creativity: 78, safety: 85 },
    latency: 180,
    costPer1kTokens: 0.001,
    contextWindow: 1000000,
  },
  {
    id: 'llama-3-70b',
    name: 'Llama 3.1 70B',
    provider: 'Meta',
    metrics: { accuracy: 82, speed: 80, cost: 85, reasoning: 80, creativity: 75, safety: 78 },
    latency: 520,
    costPer1kTokens: 0.0008,
    contextWindow: 128000,
  },
  {
    id: 'mistral-large',
    name: 'Mistral Large',
    provider: 'Mistral',
    metrics: { accuracy: 86, speed: 82, cost: 78, reasoning: 85, creativity: 80, safety: 82 },
    latency: 400,
    costPer1kTokens: 0.008,
    contextWindow: 128000,
  },
  {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    provider: 'OpenAI',
    metrics: { accuracy: 91, speed: 82, cost: 55, reasoning: 93, creativity: 86, safety: 89 },
    latency: 520,
    costPer1kTokens: 0.03,
    contextWindow: 128000,
  },
];

export const useModelComparison = () => {
  const [isLoading, setIsLoading] = useState(false);

  const generateShareUrl = useCallback(async (modelIds: string[]): Promise<string> => {
    // Encode model selection in URL
    const params = new URLSearchParams();
    params.set('models', modelIds.join(','));
    return `${window.location.origin}/compare?${params.toString()}`;
  }, []);

  const exportToPDF = useCallback(async (models: ModelData[]): Promise<void> => {
    setIsLoading(true);
    try {
      // Generate PDF content as HTML for print
      const content = generatePDFContent(models);
      const printWindow = window.open('', '_blank');
      if (printWindow) {
        printWindow.document.write(content);
        printWindow.document.close();
        printWindow.focus();
        setTimeout(() => {
          printWindow.print();
          printWindow.close();
        }, 500);
      }
    } finally {
      setIsLoading(false);
    }
  }, []);

  return {
    models: MOCK_MODELS,
    isLoading,
    generateShareUrl,
    exportToPDF,
  };
};

function generatePDFContent(models: ModelData[]): string {
  const date = new Date().toLocaleDateString();
  const modelRows = models.map(m => `
    <tr>
      <td>${m.name}</td>
      <td>${m.provider}</td>
      <td>${m.metrics.accuracy}%</td>
      <td>${m.metrics.speed}%</td>
      <td>${m.metrics.reasoning}%</td>
      <td>${m.latency}ms</td>
      <td>$${m.costPer1kTokens.toFixed(4)}</td>
      <td>${(m.contextWindow/1000).toFixed(0)}K</td>
    </tr>
  `).join('');

  return `<!DOCTYPE html><html><head><title>LLM Comparison Report</title>
<style>body{font-family:system-ui,-apple-system,sans-serif;padding:40px;max-width:1000px;margin:0 auto}
h1{color:#1f2937;border-bottom:2px solid #10b981;padding-bottom:10px}
table{width:100%;border-collapse:collapse;margin-top:20px}
th,td{border:1px solid #e5e7eb;padding:12px;text-align:left}
th{background:#f3f4f6;font-weight:600}
.footer{margin-top:40px;padding-top:20px;border-top:1px solid #e5e7eb;color:#6b7280;font-size:12px}</style>
</head><body>
<h1>LLM Model Comparison Report</h1>
<p>Generated: ${date} | Models: ${models.length}</p>
<table><thead><tr><th>Model</th><th>Provider</th><th>Accuracy</th><th>Speed</th><th>Reasoning</th><th>Latency</th><th>Cost/1K</th><th>Context</th></tr></thead>
<tbody>${modelRows}</tbody></table>
<div class="footer">Generated by LLMWorks - llmworks.dev</div>
</body></html>`;
}

