#!/usr/bin/env node

import fs from 'fs';
import path from 'path';
import { execSync } from 'child_process';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const rootDir = path.resolve(__dirname, '..');

console.log('ðŸ§ª Enterprise Testing Automation & Coverage Suite\n');

const testReport = {
  timestamp: new Date().toISOString(),
  summary: {
    totalTests: 0,
    passedTests: 0,
    failedTests: 0,
    skippedTests: 0,
    testCoverage: 0,
    overallScore: 0
  },
  testSuites: {
    unit: { status: 'unknown', tests: 0, coverage: 0, duration: 0 },
    integration: { status: 'unknown', tests: 0, coverage: 0, duration: 0 },
    e2e: { status: 'unknown', tests: 0, coverage: 0, duration: 0 },
    visual: { status: 'unknown', tests: 0, coverage: 0, duration: 0 },
    performance: { status: 'unknown', tests: 0, coverage: 0, duration: 0 }
  },
  coverage: {
    statements: 0,
    branches: 0,
    functions: 0,
    lines: 0
  },
  quality: {
    testComplexity: 0,
    duplicateTests: [],
    slowTests: [],
    flakiness: []
  },
  recommendations: [],
  alerts: []
};

// 1. ANALYZE EXISTING TEST STRUCTURE
console.log('ðŸ“Š Analyzing test structure...\n');

function analyzeTestStructure() {
  const testFiles = [];
  const testPatterns = [
    /\.test\.(ts|tsx|js|jsx)$/,
    /\.spec\.(ts|tsx|js|jsx)$/,
    /__tests__.*\.(ts|tsx|js|jsx)$/
  ];
  
  function scanForTests(dir, relativePath = '') {
    try {
      const items = fs.readdirSync(dir);
      
      items.forEach(item => {
        if (item === 'node_modules' || item === '.git' || item === 'dist') return;
        
        const itemPath = path.join(dir, item);
        const itemRelativePath = path.join(relativePath, item);
        const stat = fs.statSync(itemPath);
        
        if (stat.isDirectory()) {
          scanForTests(itemPath, itemRelativePath);
        } else if (testPatterns.some(pattern => pattern.test(item))) {
          testFiles.push({
            file: itemRelativePath,
            fullPath: itemPath,
            size: stat.size,
            type: getTestType(itemRelativePath)
          });
        }
      });
    } catch (error) {
      // Skip directories that can't be read
    }
  }
  
  scanForTests(rootDir);
  
  const testsByType = testFiles.reduce((acc, test) => {
    acc[test.type] = (acc[test.type] || 0) + 1;
    return acc;
  }, {});
  
  console.log(`ðŸ“ Found ${testFiles.length} test files:`);
  Object.entries(testsByType).forEach(([type, count]) => {
    console.log(`  â€¢ ${type}: ${count} files`);
  });
  
  console.log();
  return testFiles;
}

function getTestType(filePath) {
  if (filePath.includes('e2e') || filePath.includes('cypress') || filePath.includes('playwright')) {
    return 'e2e';
  } else if (filePath.includes('integration') || filePath.includes('api')) {
    return 'integration';
  } else if (filePath.includes('visual') || filePath.includes('screenshot')) {
    return 'visual';
  } else if (filePath.includes('performance') || filePath.includes('load')) {
    return 'performance';
  } else {
    return 'unit';
  }
}

const testFiles = analyzeTestStructure();

// 2. RUN UNIT TESTS WITH COVERAGE
console.log('ðŸ§ª Running unit tests with coverage...\n');

function runUnitTests() {
  try {
    console.log('ðŸš€ Executing unit test suite...');
    const startTime = Date.now();
    
    // Run tests with coverage
    const testOutput = execSync('npm run test:run -- --coverage --reporter=json --outputFile=unit-test-results.json 2>&1', {
      encoding: 'utf8',
      cwd: rootDir,
      timeout: 120000
    });
    
    const duration = Math.round((Date.now() - startTime) / 1000);
    testReport.testSuites.unit.duration = duration;
    
    // Parse test results if available
    if (fs.existsSync(path.join(rootDir, 'unit-test-results.json'))) {
      const results = JSON.parse(fs.readFileSync(path.join(rootDir, 'unit-test-results.json'), 'utf8'));
      
      testReport.testSuites.unit.tests = results.numTotalTests || 0;
      testReport.testSuites.unit.status = results.success ? 'passed' : 'failed';
      
      testReport.summary.totalTests += results.numTotalTests || 0;
      testReport.summary.passedTests += results.numPassedTests || 0;
      testReport.summary.failedTests += results.numFailedTests || 0;
    }
    
    // Parse coverage if available
    const coveragePath = path.join(rootDir, 'coverage/coverage-summary.json');
    if (fs.existsSync(coveragePath)) {
      const coverage = JSON.parse(fs.readFileSync(coveragePath, 'utf8'));
      
      testReport.coverage = {
        statements: Math.round(coverage.total.statements.pct),
        branches: Math.round(coverage.total.branches.pct),
        functions: Math.round(coverage.total.functions.pct),
        lines: Math.round(coverage.total.lines.pct)
      };
      
      const avgCoverage = Math.round(
        (testReport.coverage.statements + testReport.coverage.branches + 
         testReport.coverage.functions + testReport.coverage.lines) / 4
      );
      
      testReport.testSuites.unit.coverage = avgCoverage;
      testReport.summary.testCoverage = avgCoverage;
    }
    
    console.log(`âœ… Unit tests completed in ${duration}s`);
    console.log(`ðŸ“Š Coverage: ${testReport.summary.testCoverage}%`);
    
  } catch (error) {
    console.log('âš ï¸  Unit tests encountered issues, continuing...');
    testReport.testSuites.unit.status = 'failed';
    testReport.alerts.push({
      level: 'high',
      message: 'Unit tests failed or not configured',
      action: 'Configure test script and ensure tests are runnable'
    });
  }
  
  console.log();
}

runUnitTests();

// 3. GENERATE MISSING TESTS
console.log('ðŸ”¨ Generating missing test files...\n');

function generateMissingTests() {
  const componentFiles = [];
  
  // Find all components without tests
  function findComponents(dir, relativePath = '') {
    try {
      const items = fs.readdirSync(dir);
      
      items.forEach(item => {
        if (item === 'node_modules' || item === '.git' || item === 'dist') return;
        
        const itemPath = path.join(dir, item);
        const itemRelativePath = path.join(relativePath, item);
        const stat = fs.statSync(itemPath);
        
        if (stat.isDirectory()) {
          findComponents(itemPath, itemRelativePath);
        } else if (item.endsWith('.tsx') && !item.includes('.test.') && !item.includes('.spec.')) {
          // Check if test file exists
          const testFile = item.replace('.tsx', '.test.tsx');
          const testPath = path.join(dir, testFile);
          
          if (!fs.existsSync(testPath)) {
            componentFiles.push({
              component: itemRelativePath,
              componentPath: itemPath,
              testPath: testPath,
              testRelativePath: path.join(relativePath, testFile)
            });
          }
        }
      });
    } catch (error) {
      // Skip directories that can't be read
    }
  }
  
  findComponents(path.join(rootDir, 'src'));
  
  console.log(`ðŸ“ Found ${componentFiles.length} components without tests`);
  
  let generated = 0;
  componentFiles.slice(0, 10).forEach(comp => { // Limit to 10 for demo
    try {
      const testContent = generateTestTemplate(comp);
      fs.writeFileSync(comp.testPath, testContent);
      console.log(`âœ… Generated: ${comp.testRelativePath}`);
      generated++;
    } catch (error) {
      console.log(`âŒ Failed to generate: ${comp.testRelativePath}`);
    }
  });
  
  if (generated > 0) {
    testReport.recommendations.push(`Generated ${generated} test files for untested components`);
  }
  
  if (componentFiles.length > 10) {
    console.log(`âš ï¸  ${componentFiles.length - 10} more components need tests`);
    testReport.recommendations.push(`Create tests for remaining ${componentFiles.length - 10} components`);
  }
  
  console.log();
}

function generateTestTemplate(comp) {
  const componentName = path.basename(comp.component, '.tsx');
  const relativePath = path.relative(path.dirname(comp.testPath), comp.componentPath).replace(/\\/g, '/');
  
  return `import { render, screen } from '@testing-library/react';
import { describe, it, expect } from 'vitest';
import ${componentName} from '${relativePath.replace('.tsx', '')}';

describe('${componentName}', () => {
  it('renders without crashing', () => {
    render(<${componentName} />);
    expect(screen.getByRole('main')).toBeInTheDocument();
  });

  it('displays expected content', () => {
    render(<${componentName} />);
    // Add specific assertions based on component behavior
    expect(true).toBe(true); // Placeholder assertion
  });

  it('handles user interactions', () => {
    render(<${componentName} />);
    // Add interaction tests
    expect(true).toBe(true); // Placeholder assertion
  });
});
`;
}

generateMissingTests();

// 4. INTEGRATION TEST SETUP
console.log('ðŸ”— Setting up integration tests...\n');

function setupIntegrationTests() {
  const integrationTestDir = path.join(rootDir, 'tests/integration');
  
  if (!fs.existsSync(integrationTestDir)) {
    fs.mkdirSync(integrationTestDir, { recursive: true });
    console.log('ðŸ“ Created integration test directory');
  }
  
  // Create API integration test template
  const apiTestPath = path.join(integrationTestDir, 'api.test.ts');
  if (!fs.existsSync(apiTestPath)) {
    const apiTestContent = `import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = process.env.VITE_SUPABASE_URL || 'http://localhost:54321';
const supabaseKey = process.env.VITE_SUPABASE_ANON_KEY || 'test-key';

describe('API Integration Tests', () => {
  let supabase: any;

  beforeAll(() => {
    supabase = createClient(supabaseUrl, supabaseKey);
  });

  afterAll(() => {
    // Cleanup test data
  });

  describe('Authentication', () => {
    it('should handle user signup', async () => {
      // Test user registration flow
      expect(true).toBe(true); // Placeholder
    });

    it('should handle user login', async () => {
      // Test user authentication
      expect(true).toBe(true); // Placeholder
    });
  });

  describe('Data Operations', () => {
    it('should fetch user profile', async () => {
      // Test profile data retrieval
      expect(true).toBe(true); // Placeholder
    });

    it('should update user preferences', async () => {
      // Test data updates
      expect(true).toBe(true); // Placeholder
    });
  });
});
`;
    
    fs.writeFileSync(apiTestPath, apiTestContent);
    console.log('âœ… Created API integration test template');
  }
  
  // Create component integration test template
  const componentTestPath = path.join(integrationTestDir, 'components.test.tsx');
  if (!fs.existsSync(componentTestPath)) {
    const componentTestContent = `import { render, screen, waitFor } from '@testing-library/react';
import { describe, it, expect, vi } from 'vitest';
import userEvent from '@testing-library/user-event';

// Mock providers and contexts
const MockProviders = ({ children }: { children: React.ReactNode }) => {
  return (
    <div data-testid="mock-providers">
      {children}
    </div>
  );
};

describe('Component Integration Tests', () => {
  describe('Form Workflows', () => {
    it('should complete intake form flow', async () => {
      // Test multi-step form completion
      expect(true).toBe(true); // Placeholder
    });

    it('should handle form validation', async () => {
      // Test form validation across steps
      expect(true).toBe(true); // Placeholder
    });
  });

  describe('Navigation', () => {
    it('should navigate between pages', async () => {
      // Test routing and navigation
      expect(true).toBe(true); // Placeholder
    });

    it('should handle protected routes', async () => {
      // Test authentication-based routing
      expect(true).toBe(true); // Placeholder
    });
  });

  describe('Data Flow', () => {
    it('should sync data across components', async () => {
      // Test component data synchronization
      expect(true).toBe(true); // Placeholder
    });
  });
});
`;
    
    fs.writeFileSync(componentTestPath, componentTestContent);
    console.log('âœ… Created component integration test template');
  }
  
  testReport.testSuites.integration.status = 'configured';
  console.log();
}

setupIntegrationTests();

// 5. E2E TEST SETUP
console.log('ðŸŒ Setting up E2E tests...\n');

function setupE2ETests() {
  const e2eTestDir = path.join(rootDir, 'tests/e2e');
  
  if (!fs.existsSync(e2eTestDir)) {
    fs.mkdirSync(e2eTestDir, { recursive: true });
    console.log('ðŸ“ Created E2E test directory');
  }
  
  // Create Playwright config
  const playwrightConfigPath = path.join(rootDir, 'playwright.config.ts');
  if (!fs.existsSync(playwrightConfigPath)) {
    const playwrightConfig = `import { defineConfig, devices } from '@playwright/test';

export default defineConfig({
  testDir: './tests/e2e',
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: [
    ['html'],
    ['json', { outputFile: 'e2e-test-results.json' }]
  ],
  use: {
    baseURL: process.env.PLAYWRIGHT_BASE_URL || 'http://localhost:8080',
    trace: 'on-first-retry',
    screenshot: 'only-on-failure',
  },
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },
    {
      name: 'firefox',
      use: { ...devices['Desktop Firefox'] },
    },
    {
      name: 'webkit',
      use: { ...devices['Desktop Safari'] },
    },
    {
      name: 'Mobile Chrome',
      use: { ...devices['Pixel 5'] },
    },
  ],
  webServer: {
    command: 'npm run dev',
    url: 'http://localhost:8080',
    reuseExistingServer: !process.env.CI,
  },
});
`;
    
    fs.writeFileSync(playwrightConfigPath, playwrightConfig);
    console.log('âœ… Created Playwright configuration');
  }
  
  // Create sample E2E test
  const sampleE2EPath = path.join(e2eTestDir, 'auth-flow.spec.ts');
  if (!fs.existsSync(sampleE2EPath)) {
    const sampleE2EContent = `import { test, expect } from '@playwright/test';

test.describe('Authentication Flow', () => {
  test('should complete user registration', async ({ page }) => {
    await page.goto('/');
    
    // Navigate to signup
    await page.click('[data-testid="signup-button"]');
    
    // Fill registration form
    await page.fill('[data-testid="email-input"]', 'test@example.com');
    await page.fill('[data-testid="password-input"]', 'SecurePassword123!');
    await page.fill('[data-testid="confirm-password"]', 'SecurePassword123!');
    
    // Submit form
    await page.click('[data-testid="submit-button"]');
    
    // Verify success
    await expect(page).toHaveURL(/dashboard/);
    await expect(page.locator('[data-testid="welcome-message"]')).toBeVisible();
  });

  test('should handle login flow', async ({ page }) => {
    await page.goto('/login');
    
    // Fill login form
    await page.fill('[data-testid="email-input"]', 'test@example.com');
    await page.fill('[data-testid="password-input"]', 'SecurePassword123!');
    
    // Submit form
    await page.click('[data-testid="login-button"]');
    
    // Verify successful login
    await expect(page).toHaveURL(/dashboard/);
  });

  test('should handle logout', async ({ page }) => {
    // Assume user is logged in
    await page.goto('/dashboard');
    
    // Click logout
    await page.click('[data-testid="logout-button"]');
    
    // Verify redirect to home
    await expect(page).toHaveURL('/');
  });
});

test.describe('Core User Flows', () => {
  test('should complete intake process', async ({ page }) => {
    await page.goto('/intake');
    
    // Multi-step form completion
    for (let step = 1; step <= 7; step++) {
      await page.fill(\`[data-testid="step-\${step}-input"]\`, 'Test data');
      await page.click('[data-testid="next-button"]');
    }
    
    // Verify completion
    await expect(page.locator('[data-testid="intake-complete"]')).toBeVisible();
  });
});
`;
    
    fs.writeFileSync(sampleE2EPath, sampleE2EContent);
    console.log('âœ… Created sample E2E test');
  }
  
  testReport.testSuites.e2e.status = 'configured';
  console.log();
}

setupE2ETests();

// 6. PERFORMANCE TESTING SETUP
console.log('âš¡ Setting up performance tests...\n');

function setupPerformanceTests() {
  const perfTestDir = path.join(rootDir, 'tests/performance');
  
  if (!fs.existsSync(perfTestDir)) {
    fs.mkdirSync(perfTestDir, { recursive: true });
    console.log('ðŸ“ Created performance test directory');
  }
  
  // Create Lighthouse CI config
  const lighthouseConfigPath = path.join(rootDir, 'lighthouserc.json');
  if (!fs.existsSync(lighthouseConfigPath)) {
    const lighthouseConfig = {
      ci: {
        collect: {
          url: ['http://localhost:8080'],
          numberOfRuns: 3,
          settings: {
            chromeFlags: '--no-sandbox --disable-dev-shm-usage'
          }
        },
        assert: {
          assertions: {
            'categories:performance': ['error', { minScore: 0.8 }],
            'categories:accessibility': ['error', { minScore: 0.9 }],
            'categories:best-practices': ['error', { minScore: 0.8 }],
            'categories:seo': ['error', { minScore: 0.8 }],
            'first-contentful-paint': ['error', { maxNumericValue: 2000 }],
            'largest-contentful-paint': ['error', { maxNumericValue: 4000 }],
            'cumulative-layout-shift': ['error', { maxNumericValue: 0.1 }]
          }
        },
        upload: {
          target: 'temporary-public-storage'
        }
      }
    };
    
    fs.writeFileSync(lighthouseConfigPath, JSON.stringify(lighthouseConfig, null, 2));
    console.log('âœ… Created Lighthouse CI configuration');
  }
  
  // Create load testing script
  const loadTestPath = path.join(perfTestDir, 'load-test.js');
  if (!fs.existsSync(loadTestPath)) {
    const loadTestContent = `import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

export let errorRate = new Rate('errors');

export let options = {
  stages: [
    { duration: '2m', target: 10 }, // Ramp up
    { duration: '5m', target: 50 }, // Stay at 50 users
    { duration: '2m', target: 0 },  // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)<2000'], // 95% of requests must complete below 2s
    errors: ['rate<0.1'], // Error rate should be less than 10%
  },
};

const BASE_URL = __ENV.BASE_URL || 'http://localhost:8080';

export default function () {
  // Test home page
  let response = http.get(\`\${BASE_URL}/\`);
  check(response, {
    'home page loads': (r) => r.status === 200,
    'home page response time < 2s': (r) => r.timings.duration < 2000,
  }) || errorRate.add(1);
  
  sleep(1);
  
  // Test API endpoints
  response = http.get(\`\${BASE_URL}/api/health\`);
  check(response, {
    'health check passes': (r) => r.status === 200,
    'health check fast': (r) => r.timings.duration < 500,
  }) || errorRate.add(1);
  
  sleep(2);
}
`;
    
    fs.writeFileSync(loadTestPath, loadTestContent);
    console.log('âœ… Created load testing script');
  }
  
  testReport.testSuites.performance.status = 'configured';
  console.log();
}

setupPerformanceTests();

// 7. TEST QUALITY ANALYSIS
console.log('ðŸ“Š Analyzing test quality...\n');

function analyzeTestQuality() {
  const qualityIssues = [];
  
  // Check for slow tests
  if (testReport.testSuites.unit.duration > 30) {
    qualityIssues.push({
      type: 'slow-tests',
      message: `Unit tests are slow (${testReport.testSuites.unit.duration}s)`,
      recommendation: 'Optimize test setup and teardown, mock heavy dependencies'
    });
  }
  
  // Check coverage thresholds
  if (testReport.summary.testCoverage < 80) {
    qualityIssues.push({
      type: 'low-coverage',
      message: `Test coverage is ${testReport.summary.testCoverage}% (target: 80%+)`,
      recommendation: 'Add tests for uncovered code paths'
    });
  }
  
  // Check test distribution
  const testRatio = testFiles.length / 324; // 324 components found earlier
  if (testRatio < 0.5) {
    qualityIssues.push({
      type: 'insufficient-tests',
      message: `Only ${Math.round(testRatio * 100)}% of components have tests`,
      recommendation: 'Create tests for remaining components'
    });
  }
  
  testReport.quality.testComplexity = qualityIssues.length;
  
  if (qualityIssues.length > 0) {
    console.log(`âš ï¸  Found ${qualityIssues.length} quality issues:`);
    qualityIssues.forEach(issue => {
      console.log(`  â€¢ ${issue.message}`);
    });
  } else {
    console.log('âœ… Test quality looks good!');
  }
  
  console.log();
  return qualityIssues;
}

const qualityIssues = analyzeTestQuality();

// 8. GENERATE TESTING RECOMMENDATIONS
function generateTestingRecommendations() {
  const recommendations = [];
  
  if (testReport.summary.testCoverage < 80) {
    recommendations.push('Increase test coverage to 80%+ for better reliability');
  }
  
  if (testReport.testSuites.unit.status === 'failed') {
    recommendations.push('Fix failing unit tests before deployment');
  }
  
  if (testReport.testSuites.integration.status !== 'configured') {
    recommendations.push('Set up integration tests for API and component workflows');
  }
  
  if (testReport.testSuites.e2e.status !== 'configured') {
    recommendations.push('Implement E2E tests for critical user journeys');
  }
  
  recommendations.push('Set up automated test execution in CI/CD pipeline');
  recommendations.push('Implement visual regression testing for UI components');
  recommendations.push('Add performance testing for critical user flows');
  recommendations.push('Set up test data management and cleanup automation');
  
  testReport.recommendations = recommendations;
}

generateTestingRecommendations();

// 9. CALCULATE OVERALL TESTING SCORE
function calculateTestingScore() {
  let score = 0;
  
  // Coverage contribution (40%)
  score += (testReport.summary.testCoverage / 100) * 40;
  
  // Test existence contribution (30%)
  const testRatio = Math.min(testFiles.length / 100, 1); // Cap at 100 files
  score += testRatio * 30;
  
  // Test suite setup contribution (20%)
  const suiteCount = Object.values(testReport.testSuites).filter(s => s.status !== 'unknown').length;
  score += (suiteCount / 5) * 20;
  
  // Quality contribution (10%)
  const qualityScore = Math.max(0, 100 - (qualityIssues.length * 10));
  score += (qualityScore / 100) * 10;
  
  testReport.summary.overallScore = Math.round(score);
}

calculateTestingScore();

// 10. CREATE TEST AUTOMATION SCRIPTS
console.log('ðŸ¤– Creating test automation scripts...\n');

function createTestAutomationScripts() {
  // Create comprehensive test runner
  const testRunnerScript = `#!/bin/bash
# Enterprise Test Automation Runner

echo "ðŸ§ª Starting Enterprise Test Suite..."
echo "====================================="

# Set error handling
set -e

# Change to project directory
cd "$(dirname "$0")/.."

# Function to run tests with retry
run_with_retry() {
  local cmd="$1"
  local description="$2"
  local max_attempts=3
  local attempt=1
  
  while [ $attempt -le $max_attempts ]; do
    echo "Attempt $attempt/$max_attempts: $description"
    if eval "$cmd"; then
      echo "âœ… $description completed successfully"
      return 0
    else
      echo "âŒ $description failed (attempt $attempt/$max_attempts)"
      if [ $attempt -eq $max_attempts ]; then
        echo "ðŸš¨ $description failed after $max_attempts attempts"
        return 1
      fi
      attempt=$((attempt + 1))
      sleep 5
    fi
  done
}

echo "ðŸ“¦ Installing dependencies..."
npm ci --prefer-offline --no-audit

echo ""
echo "ðŸ§ª Running Unit Tests..."
run_with_retry "npm run test:run -- --coverage" "Unit Tests"

echo ""
echo "ðŸ”— Running Integration Tests..."
if [ -d "tests/integration" ]; then
  run_with_retry "npm run test:integration" "Integration Tests"
else
  echo "âš ï¸  Integration tests not configured"
fi

echo ""
echo "ðŸŒ Running E2E Tests..."
if [ -f "playwright.config.ts" ]; then
  run_with_retry "npx playwright test" "E2E Tests"
else
  echo "âš ï¸  E2E tests not configured"
fi

echo ""
echo "âš¡ Running Performance Tests..."
if [ -f "lighthouserc.json" ]; then
  run_with_retry "npm run build && npx lhci autorun" "Performance Tests"
else
  echo "âš ï¸  Performance tests not configured"
fi

echo ""
echo "ðŸ“Š Generating Test Report..."
node scripts/enterprise-test-automation.mjs

echo ""
echo "====================================="
echo "âœ… Enterprise Test Suite Complete!"
echo "ðŸ“„ Check test-automation-report.json for detailed results"
`;

  fs.writeFileSync(path.join(rootDir, 'scripts/run-all-tests.sh'), testRunnerScript);
  
  try {
    fs.chmodSync(path.join(rootDir, 'scripts/run-all-tests.sh'), '755');
  } catch (error) {
    // chmod might not work on all systems
  }
  
  // Update package.json with test scripts
  const packageJsonPath = path.join(rootDir, 'package.json');
  if (fs.existsSync(packageJsonPath)) {
    try {
      const packageJson = JSON.parse(fs.readFileSync(packageJsonPath, 'utf8'));
      
      packageJson.scripts = {
        ...packageJson.scripts,
        'test:integration': 'vitest run tests/integration',
        'test:e2e': 'playwright test',
        'test:performance': 'lhci autorun',
        'test:load': 'k6 run tests/performance/load-test.js',
        'test:all': './scripts/run-all-tests.sh'
      };
      
      fs.writeFileSync(packageJsonPath, JSON.stringify(packageJson, null, 2));
      console.log('âœ… Updated package.json with test scripts');
    } catch (error) {
      console.log('âš ï¸  Could not update package.json');
    }
  }
  
  console.log('âœ… Created test automation scripts');
  console.log();
}

createTestAutomationScripts();

// 11. SAVE TEST REPORT
fs.writeFileSync(
  path.join(rootDir, 'test-automation-report.json'),
  JSON.stringify(testReport, null, 2)
);

// 12. DISPLAY TEST AUTOMATION DASHBOARD
console.log('ðŸ§ª Enterprise Testing Automation Dashboard');
console.log('â•'.repeat(60));
console.log(`ðŸ“Š Overall Score: ${testReport.summary.overallScore}/100`);
console.log(`ðŸŽ¯ Test Coverage: ${testReport.summary.testCoverage}%`);
console.log(`ðŸ“ Test Files: ${testFiles.length}`);
console.log(`âœ… Passed: ${testReport.summary.passedTests}`);
console.log(`âŒ Failed: ${testReport.summary.failedTests}`);
console.log('â•'.repeat(60));

console.log('\nðŸ§ª Test Suite Status:');
Object.entries(testReport.testSuites).forEach(([suite, data]) => {
  const statusIcon = data.status === 'passed' ? 'âœ…' :
                    data.status === 'failed' ? 'âŒ' :
                    data.status === 'configured' ? 'ðŸ”§' : 'âšª';
  console.log(`${statusIcon} ${suite.padEnd(15)} | ${data.status.padEnd(10)} | Coverage: ${data.coverage}%`);
});

console.log('\nðŸ“Š Coverage Breakdown:');
console.log(`ðŸ“ Statements: ${testReport.coverage.statements}%`);
console.log(`ðŸŒ¿ Branches: ${testReport.coverage.branches}%`);
console.log(`âš™ï¸  Functions: ${testReport.coverage.functions}%`);
console.log(`ðŸ“ Lines: ${testReport.coverage.lines}%`);

if (testReport.recommendations.length > 0) {
  console.log('\nðŸ’¡ Testing Recommendations:');
  testReport.recommendations.forEach((rec, i) => {
    console.log(`  ${i + 1}. ${rec}`);
  });
}

console.log('\nðŸš€ Quick Commands:');
console.log('  â€¢ Run all tests: ./scripts/run-all-tests.sh');
console.log('  â€¢ Unit tests: npm run test:run');
console.log('  â€¢ E2E tests: npm run test:e2e');
console.log('  â€¢ Performance: npm run test:performance');

console.log('\nðŸ“„ Test automation report saved to: test-automation-report.json');
console.log('\nðŸ§ª Test automation setup complete!');

process.exit(0);