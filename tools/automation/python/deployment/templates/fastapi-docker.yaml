# Docker Compose for FastAPI Services
# For API projects like MeatheadPhysicist/API

version: "3.8"

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    image: ${PROJECT_NAME:-api}:${VERSION:-latest}
    container_name: ${PROJECT_NAME:-api}
    restart: unless-stopped
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379
      - SECRET_KEY=${SECRET_KEY}
      - CORS_ORIGINS=${CORS_ORIGINS:-*}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - api-network
    volumes:
      - ./logs:/app/logs

  db:
    image: postgres:15-alpine
    container_name: ${PROJECT_NAME:-api}-db
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME:-api}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - api-network

  redis:
    image: redis:7-alpine
    container_name: ${PROJECT_NAME:-api}-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - api-network

  # Background worker (Celery)
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    image: ${PROJECT_NAME:-api}:${VERSION:-latest}
    container_name: ${PROJECT_NAME:-api}-worker
    restart: unless-stopped
    command: celery -A app.worker worker -l info
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
    networks:
      - api-network

  # Celery Beat scheduler
  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    image: ${PROJECT_NAME:-api}:${VERSION:-latest}
    container_name: ${PROJECT_NAME:-api}-scheduler
    restart: unless-stopped
    command: celery -A app.worker beat -l info
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
    networks:
      - api-network

networks:
  api-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:

---
# Dockerfile for FastAPI
# Save as Dockerfile in project root

# syntax=docker/dockerfile:1
FROM python:3.11-slim as builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements.txt

# Production image
FROM python:3.11-slim

WORKDIR /app

# Create non-root user
RUN addgroup --system app && adduser --system --group app

# Install runtime dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy wheels and install
COPY --from=builder /app/wheels /wheels
RUN pip install --no-cache /wheels/*

# Copy application
COPY --chown=app:app . .

USER app

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
