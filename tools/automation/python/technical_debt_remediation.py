#!/usr/bin/env python3
"""
Technical Debt Remediation System

Leverages parallel workflow execution and multi-agent debate to systematically
identify, prioritize, and resolve technical debt and codebase decay issues.
"""

import asyncio
import time
import uuid
import os
import json
import subprocess
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

try:
    import yaml
except ImportError:  # pragma: no cover - optional dependency
    yaml = None

from workflow_types import TaskResult, TaskStatus, ParallelTask, TaskPriority
from claude_http_integration import ClaudeHTTPDebateCoordinator, AgentPersona


class DebtType(Enum):
    """Types of technical debt."""
    CODE_COMPLEXITY = "code_complexity"
    NAMING_CONSISTENCY = "naming_consistency"
    DOCUMENTATION_DRIFT = "documentation_drift"
    ARCHITECTURAL_VIOLATIONS = "architectural_violations"
    SECURITY_ISSUES = "security_issues"
    PERFORMANCE_BOTTLENECKS = "performance_bottlenecks"
    TEST_COVERAGE_GAPS = "test_coverage_gaps"
    DEPENDENCY_BLOAT = "dependency_bloat"


class DebtSeverity(Enum):
    """Severity levels for technical debt."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


def load_security_scanning_policy() -> Dict[str, Any]:
    """Load security scanning policy from YAML, with safe defaults.

    The default configuration matches the in-code behavior used previously,
    so behavior is unchanged if the policy file or PyYAML are unavailable.
    """

    default_policy: Dict[str, Any] = {
        "languages": {
            "python": {
                "hardcoded_secrets": [
                    {
                        "id": "SEC_PWD",
                        "pattern": r"\\bpassword\\s*=\\s*['\"][^'\"]+['\"]",
                        "severity": "critical",
                        "message": "Potential hardcoded password",
                    },
                    {
                        "id": "SEC_API_KEY",
                        "pattern": r"\\bapi_key\\s*=\\s*['\"][^'\"]+['\"]",
                        "severity": "critical",
                        "message": "Potential hardcoded API key",
                    },
                    {
                        "id": "SEC_SECRET",
                        "pattern": r"\\bsecret\\s*=\\s*['\"][^'\"]+['\"]",
                        "severity": "critical",
                        "message": "Potential hardcoded secret",
                    },
                    {
                        "id": "SEC_TOKEN",
                        "pattern": r"\\btoken\\s*=\\s*['\"][^'\"]+['\"]",
                        "severity": "critical",
                        "message": "Potential hardcoded token",
                    },
                ]
            }
        },
        "excludes": {
            "paths": ["examples/**", "docs/**"],
            "markers": ["# Example only", "# DEMO ONLY"],
        },
    }

    policy_path = (
        Path(__file__).parent
        / "governance"
        / "policies"
        / "security_scanning.yaml"
    )

    if yaml is None or not policy_path.exists():
        return default_policy

    try:
        with policy_path.open("r", encoding="utf-8") as f:
            data = yaml.safe_load(f) or {}
    except Exception:
        return default_policy

    # Merge with defaults so we always have the expected keys
    languages = data.get("languages") or default_policy["languages"]
    excludes = data.get("excludes") or default_policy["excludes"]

    return {"languages": languages, "excludes": excludes}


@dataclass
class TechnicalDebtItem:
    """Represents a technical debt item."""
    id: str
    type: DebtType
    severity: DebtSeverity
    description: str
    file_path: str
    line_number: Optional[int]
    estimated_effort: int  # hours
    business_impact: str
    remediation_suggestion: str
    discovered_at: float
    metadata: Dict[str, Any]


@dataclass
class DebtAssessment:
    """Results of technical debt assessment."""
    total_debt_items: int
    debt_by_type: Dict[DebtType, int]
    debt_by_severity: Dict[DebtSeverity, int]
    estimated_remediation_time: int  # hours
    priority_items: List[TechnicalDebtItem]
    assessment_timestamp: float


class TechnicalDebtScanner:
    """Scans codebase for technical debt issues."""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.debt_items: List[TechnicalDebtItem] = []

    async def scan_all_issues(self) -> DebtAssessment:
        """Comprehensive technical debt scan."""
        print(f"ðŸ” Scanning {self.project_root} for technical debt...")

        # Run all scanners in parallel
        scanners = [
            self._scan_code_complexity(),
            self._scan_naming_consistency(),
            self._scan_documentation_drift(),
            self._scan_architectural_violations(),
            self._scan_security_issues(),
            self._scan_performance_issues(),
            self._scan_test_coverage(),
            self._scan_dependency_bloat()
        ]

        results = await asyncio.gather(*scanners, return_exceptions=True)

        # Process results
        for result in results:
            if isinstance(result, list):
                self.debt_items.extend(result)
            elif isinstance(result, Exception):
                print(f"âš ï¸ Scanner error: {result}")

        # Create assessment
        assessment = self._create_assessment()
        print(f"ðŸ“Š Found {assessment.total_debt_items} technical debt items")

        return assessment

    async def _scan_code_complexity(self) -> List[TechnicalDebtItem]:
        """Scan for overly complex code."""
        print("   ðŸ” Scanning code complexity...")
        items = []

        # Find Python files
        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files[:20]:  # Limit for demo
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                lines = content.split('\n')
                in_multiline_string = False
                multiline_quote = None  # Track which quote style opened the string

                for i, line in enumerate(lines, 1):
                    # Handle multi-line string tracking
                    if in_multiline_string:
                        # Check if this line closes the multi-line string
                        if multiline_quote and multiline_quote in line:
                            in_multiline_string = False
                            multiline_quote = None
                        continue

                    # Check if this line opens a multi-line string
                    for quote in ('"""', "'''"):
                        if quote in line:
                            count = line.count(quote)
                            if count == 1:
                                # Opens but doesn't close on same line
                                in_multiline_string = True
                                multiline_quote = quote
                                break
                            # If count >= 2, it opens and closes on same line, no state change

                    # Skip lines that are inside or start multi-line strings
                    if in_multiline_string:
                        continue

                    stripped = line.lstrip()
                    # Skip empty lines, comments, and lines that are string literals
                    if not stripped or stripped.startswith('#'):
                        continue
                    # Skip lines that are just string content (start with quotes)
                    if stripped.startswith(('"""', "'''", '"', "'")):
                        continue

                    # Check for complex functions (long lines)
                    if len(line) > 120:
                        items.append(TechnicalDebtItem(
                            id=f"complex_line_{uuid.uuid4().hex[:8]}",
                            type=DebtType.CODE_COMPLEXITY,
                            severity=DebtSeverity.MEDIUM,
                            description=f"Line too long ({len(line)} characters)",
                            file_path=str(file_path),
                            line_number=i,
                            estimated_effort=1,
                            business_impact="Reduced readability",
                            remediation_suggestion="Break long line into multiple lines",
                            discovered_at=time.time(),
                            metadata={"line_length": len(line)}
                        ))

                    # Check for nested complexity based on indentation depth
                    leading_spaces = len(line) - len(line.lstrip(' '))
                    leading_tabs = len(line) - len(line.lstrip('\t'))
                    indent_score = leading_spaces + (leading_tabs * 4)

                    # Skip data structure content (dict/list items, function args)
                    # These are often deeply indented but not complex logic
                    if stripped.startswith(('{', '}', '[', ']', '(', ')', ',')):
                        continue
                    if stripped.endswith((',', ':', '{', '[', '(')):
                        continue

                    # Flag lines with 6+ indentation levels as genuinely complex
                    if indent_score >= 24:
                        items.append(TechnicalDebtItem(
                            id=f"nested_complex_{uuid.uuid4().hex[:8]}",
                            type=DebtType.CODE_COMPLEXITY,
                            severity=DebtSeverity.HIGH,
                            description="Deeply nested code detected",
                            file_path=str(file_path),
                            line_number=i,
                            estimated_effort=2,
                            business_impact="Difficult to understand and maintain",
                            remediation_suggestion="Extract nested logic into separate functions",
                            discovered_at=time.time(),
                            metadata={"indentation_level": indent_score // 4}
                        ))

            except Exception as e:
                print(f"     âš ï¸ Error scanning {file_path}: {e}")

        return items

    async def _scan_naming_consistency(self) -> List[TechnicalDebtItem]:
        """Scan for naming convention violations."""
        print("   ðŸ” Scanning naming consistency...")
        items = []

        # Common camelCase patterns that are acceptable in Python
        allowed_patterns = {
            'http', 'https', 'JSON', 'XML', 'HTML', 'URL', 'API', 'ID', 'UUID',
            'OAuth', 'GitHub', 'GitLab', 'PyPI', 'asyncio', 'dataclass',
        }

        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files[:20]:  # Limit for demo
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                lines = content.split('\n')
                for i, line in enumerate(lines, 1):
                    stripped = line.strip()

                    # Skip class definitions (PascalCase is correct for classes)
                    if stripped.startswith('class '):
                        continue
                    # Skip imports (external libraries may use camelCase)
                    if stripped.startswith(('import ', 'from ')):
                        continue
                    # Skip type hints and annotations
                    if ': ' in stripped and not '=' in stripped.split(':')[0]:
                        continue

                    # Check for camelCase variable/function names (not class names)
                    # Pattern: lowercase start, then mixed case (variable/function style)
                    camel_case_pattern = r'\b([a-z][a-z0-9]*[A-Z][a-zA-Z0-9]*)\s*='
                    matches = re.findall(camel_case_pattern, line)

                    for match in matches:
                        if not any(p in match for p in allowed_patterns):
                            items.append(TechnicalDebtItem(
                                id=f"naming_{uuid.uuid4().hex[:8]}",
                                type=DebtType.NAMING_CONSISTENCY,
                                severity=DebtSeverity.LOW,
                                description=f"Inconsistent naming: {match}",
                                file_path=str(file_path),
                                line_number=i,
                                estimated_effort=1,
                                business_impact="Reduced code consistency",
                                remediation_suggestion=f"Convert {match} to snake_case",
                                discovered_at=time.time(),
                                metadata={"violation": match}
                            ))

            except Exception as e:
                print(f"     âš ï¸ Error scanning {file_path}: {e}")

        return items

    async def _scan_documentation_drift(self) -> List[TechnicalDebtItem]:
        """Scan for documentation issues."""
        print("   ðŸ” Scanning documentation drift...")
        items = []

        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files[:20]:  # Limit for demo
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Check for undocumented functions
                functions = re.findall(r'def\s+(\w+)', content)
                docstrings = re.findall(r'def\s+\w+\s*\([^)]*\):\s*"""', content)

                if len(functions) > len(docstrings) + 2:  # Allow some exceptions
                    items.append(TechnicalDebtItem(
                        id=f"doc_missing_{uuid.uuid4().hex[:8]}",
                        type=DebtType.DOCUMENTATION_DRIFT,
                        severity=DebtSeverity.MEDIUM,
                        description=f"Missing documentation for {len(functions) - len(docstrings)} functions",
                        file_path=str(file_path),
                        line_number=1,
                        estimated_effort=len(functions) - len(docstrings),
                        business_impact="Reduced code understandability",
                        remediation_suggestion="Add docstrings to all functions",
                        discovered_at=time.time(),
                        metadata={"functions": len(functions), "docstrings": len(docstrings)}
                    ))

            except Exception as e:
                print(f"     âš ï¸ Error scanning {file_path}: {e}")

        return items

    async def _scan_architectural_violations(self) -> List[TechnicalDebtItem]:
        """Scan for architectural violations."""
        print("   ðŸ” Scanning architectural violations...")
        items = []

        # Check for circular imports
        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files[:10]:  # Limit for demo
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Look for potential architectural issues
                if content.count('import') > 15:
                    items.append(TechnicalDebtItem(
                        id=f"arch_imports_{uuid.uuid4().hex[:8]}",
                        type=DebtType.ARCHITECTURAL_VIOLATIONS,
                        severity=DebtSeverity.HIGH,
                        description=f"Too many imports ({content.count('import')}) suggests poor modularization",
                        file_path=str(file_path),
                        line_number=1,
                        estimated_effort=4,
                        business_impact="Tight coupling, reduced maintainability",
                        remediation_suggestion="Refactor into smaller, focused modules",
                        discovered_at=time.time(),
                        metadata={"import_count": content.count('import')}
                    ))

            except Exception as e:
                print(f"     âš ï¸ Error scanning {file_path}: {e}")

        return items

    async def _scan_security_issues(self) -> List[TechnicalDebtItem]:
        """Scan for security issues."""
        print("   ðŸ” Scanning security issues...")
        items = []

        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files[:20]:  # Limit for demo
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                policy = load_security_scanning_policy()
                lang_conf = policy.get("languages", {}).get("python", {})
                rules = lang_conf.get("hardcoded_secrets", [])
                secret_patterns = [r.get("pattern") for r in rules if r.get("pattern")]

                excludes = policy.get("excludes", {})
                exclude_paths = excludes.get("paths", [])
                exclude_markers = excludes.get("markers", [])

                # Basic path-based exclusion: skip files under simple excluded roots
                try:
                    rel_path = file_path.relative_to(self.project_root)
                    rel_parts = set(rel_path.parts)
                except Exception:
                    rel_parts = set()

                skip_file = False
                for pattern in exclude_paths:
                    root = (pattern.split("/", 1)[0] or pattern).strip()
                    if root and root in rel_parts:
                        skip_file = True
                        break

                if skip_file:
                    continue

                lines = content.split('\n')
                for i, line in enumerate(lines, 1):
                    # Skip lines that are explicitly marked as examples/demos
                    if any(marker in line for marker in exclude_markers):
                        continue

                    # Check for hardcoded secrets using configured patterns
                    for pattern in secret_patterns:
                        if pattern and re.search(pattern, line, re.IGNORECASE):
                            items.append(TechnicalDebtItem(
                                id=f"security_{uuid.uuid4().hex[:8]}",
                                type=DebtType.SECURITY_ISSUES,
                                severity=DebtSeverity.CRITICAL,
                                description="Potential hardcoded secret detected",
                                file_path=str(file_path),
                                line_number=i,
                                estimated_effort=2,
                                business_impact="Security vulnerability",
                                remediation_suggestion="Move secret to environment variables or secure storage",
                                discovered_at=time.time(),
                                metadata={"pattern": pattern}
                            ))

            except Exception as e:
                print(f"     âš ï¸ Error scanning {file_path}: {e}")

        return items

    async def _scan_performance_issues(self) -> List[TechnicalDebtItem]:
        """Scan for performance issues."""
        print("   ðŸ” Scanning performance issues...")
        items = []

        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files[:20]:  # Limit for demo
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                lines = content.split('\n')
                for i, line in enumerate(lines, 1):
                    # Check for performance anti-patterns
                    if 'for.*in.*range(len(' in line:
                        items.append(TechnicalDebtItem(
                            id=f"perf_range_{uuid.uuid4().hex[:8]}",
                            type=DebtType.PERFORMANCE_BOTTLENECKS,
                            severity=DebtSeverity.MEDIUM,
                            description="Using range(len()) pattern instead of direct iteration",
                            file_path=str(file_path),
                            line_number=i,
                            estimated_effort=1,
                            business_impact="Suboptimal performance",
                            remediation_suggestion="Use direct iteration or enumerate()",
                            discovered_at=time.time(),
                            metadata={"pattern": "range(len())"}
                        ))

                    if line.count('.append(') > 3:
                        items.append(TechnicalDebtItem(
                            id=f"perf_append_{uuid.uuid4().hex[:8]}",
                            type=DebtType.PERFORMANCE_BOTTLENECKS,
                            severity=DebtSeverity.LOW,
                            description="Multiple .append() calls in loop",
                            file_path=str(file_path),
                            line_number=i,
                            estimated_effort=1,
                            business_impact="Potential performance issue",
                            remediation_suggestion="Consider list comprehension or extend()",
                            discovered_at=time.time(),
                            metadata={"append_count": line.count('.append(')}
                        ))

            except Exception as e:
                print(f"     âš ï¸ Error scanning {file_path}: {e}")

        return items

    async def _scan_test_coverage(self) -> List[TechnicalDebtItem]:
        """Scan for test coverage gaps."""
        print("   ðŸ” Scanning test coverage...")
        items = []

        # Count source vs test files
        source_files = list(self.project_root.rglob("*.py"))
        test_files = list(self.project_root.rglob("*test*.py"))

        source_count = len([f for f in source_files if 'test' not in f.name.lower()])
        test_count = len(test_files)

        if source_count > 0 and test_count / source_count < 0.5:
            items.append(TechnicalDebtItem(
                id=f"test_coverage_{uuid.uuid4().hex[:8]}",
                type=DebtType.TEST_COVERAGE_GAPS,
                severity=DebtSeverity.HIGH,
                description=f"Low test coverage: {test_count}/{source_count} files have tests",
                file_path=str(self.project_root),
                line_number=None,
                estimated_effort=source_count - test_count,
                business_impact="Higher bug risk, reduced confidence in changes",
                remediation_suggestion="Add unit tests for all modules",
                discovered_at=time.time(),
                metadata={"source_files": source_count, "test_files": test_count}
            ))

        return items

    async def _scan_dependency_bloat(self) -> List[TechnicalDebtItem]:
        """Scan for dependency issues."""
        print("   ðŸ” Scanning dependency bloat...")
        items = []

        # Check for requirements.txt or package.json
        req_files = list(self.project_root.rglob("requirements*.txt"))
        package_files = list(self.project_root.rglob("package.json"))

        for req_file in req_files:
            try:
                with open(req_file, 'r') as f:
                    dependencies = [line.strip() for line in f if line.strip() and not line.startswith('#')]

                if len(dependencies) > 50:
                    items.append(TechnicalDebtItem(
                        id=f"deps_bloat_{uuid.uuid4().hex[:8]}",
                        type=DebtType.DEPENDENCY_BLOAT,
                        severity=DebtSeverity.MEDIUM,
                        description=f"Many dependencies ({len(dependencies)}) may indicate bloat",
                        file_path=str(req_file),
                        line_number=None,
                        estimated_effort=4,
                        business_impact="Increased attack surface, maintenance overhead",
                        remediation_suggestion="Review and remove unused dependencies",
                        discovered_at=time.time(),
                        metadata={"dependency_count": len(dependencies)}
                    ))

            except Exception as e:
                print(f"     âš ï¸ Error reading {req_file}: {e}")

        return items

    def _create_assessment(self) -> DebtAssessment:
        """Create debt assessment from scanned items."""
        debt_by_type = {}
        debt_by_severity = {}
        total_effort = 0

        for item in self.debt_items:
            debt_by_type[item.type] = debt_by_type.get(item.type, 0) + 1
            debt_by_severity[item.severity] = debt_by_severity.get(item.severity, 0) + 1
            total_effort += item.estimated_effort

        # Priority items: Critical and High severity
        priority_items = [item for item in self.debt_items
                         if item.severity in [DebtSeverity.CRITICAL, DebtSeverity.HIGH]]

        return DebtAssessment(
            total_debt_items=len(self.debt_items),
            debt_by_type=debt_by_type,
            debt_by_severity=debt_by_severity,
            estimated_remediation_time=total_effort,
            priority_items=priority_items[:10],  # Top 10 priority items
            assessment_timestamp=time.time()
        )


class TechnicalDebatePrioritizer:
    """Uses multi-agent debate to prioritize technical debt remediation."""

    def __init__(self):
        self.debate_coordinator = ClaudeHTTPDebateCoordinator()

    async def prioritize_debt_items(self, debt_items: List[TechnicalDebtItem],
                                   available_hours: int = 40) -> List[TechnicalDebtItem]:
        """Use AI debate to prioritize technical debt items."""

        if not debt_items:
            return []

        print(f"ðŸ¤– Using AI debate to prioritize {len(debt_items)} debt items...")

        # Create debate topic
        debt_summary = self._create_debt_summary(debt_items)

        topic = f"Technical Debt Prioritization for {available_hours} hours available"
        context = {
            "debt_items": debt_summary,
            "available_hours": available_hours,
            "business_context": "Software maintenance and quality improvement",
            "team_capacity": "2 developers"
        }

        # Initiate debate
        debate_id = await self.debate_coordinator.initiate_debate(topic, context)

        # Simulate AI prioritization (in real implementation, parse debate results)
        prioritized_items = self._simulate_ai_prioritization(debt_items, available_hours)

        return prioritized_items

    def _create_debt_summary(self, debt_items: List[TechnicalDebtItem]) -> str:
        """Create summary of debt items for debate."""
        summary = "Technical Debt Items:\n"

        for i, item in enumerate(debt_items[:10], 1):  # Limit for demo
            summary += f"{i}. {item.type.value} - {item.severity.value} - {item.description}\n"
            summary += f"   File: {item.file_path}, Effort: {item.estimated_effort}h\n"
            summary += f"   Impact: {item.business_impact}\n\n"

        if len(debt_items) > 10:
            summary += f"... and {len(debt_items) - 10} more items\n"

        return summary

    def _simulate_ai_prioritization(self, debt_items: List[TechnicalDebtItem],
                                  available_hours: int) -> List[TechnicalDebtItem]:
        """Simulate AI prioritization based on severity and effort."""

        # Sort by severity and effort ratio
        severity_weight = {
            DebtSeverity.CRITICAL: 4,
            DebtSeverity.HIGH: 3,
            DebtSeverity.MEDIUM: 2,
            DebtSeverity.LOW: 1
        }

        def priority_score(item):
            return severity_weight[item.severity] / max(item.estimated_effort, 1)

        prioritized = sorted(debt_items, key=priority_score, reverse=True)

        # Select items that fit within available hours
        selected = []
        hours_used = 0

        for item in prioritized:
            if hours_used + item.estimated_effort <= available_hours:
                selected.append(item)
                hours_used += item.estimated_effort

        print(f"   ðŸ“Š AI prioritized {len(selected)} items within {available_hours} hours")
        return selected


class TechnicalDebtRemediator:
    """Remediates technical debt items using parallel execution."""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.remediation_log = []

    async def remediate_items(self, items: List[TechnicalDebtItem]) -> Dict[str, Any]:
        """Remediate technical debt items in parallel."""

        print(f"ðŸ”§ Beginning remediation of {len(items)} items...")

        # Group items by type for parallel processing
        items_by_type = {}
        for item in items:
            if item.type not in items_by_type:
                items_by_type[item.type] = []
            items_by_type[item.type].append(item)

        # Process each type in parallel
        remediation_tasks = []
        for debt_type, type_items in items_by_type.items():
            task = asyncio.create_task(
                self._remediate_by_type(debt_type, type_items)
            )
            remediation_tasks.append(task)

        results = await asyncio.gather(*remediation_tasks, return_exceptions=True)

        # Process results
        successful_remediations = 0
        failed_remediations = 0

        for result in results:
            if isinstance(result, dict):
                successful_remediations += result.get('success', 0)
                failed_remediations += result.get('failed', 0)
            elif isinstance(result, Exception):
                print(f"âš ï¸ Remediation error: {result}")
                failed_remediations += 1

        return {
            'total_items': len(items),
            'successful': successful_remediations,
            'failed': failed_remediations,
            'success_rate': successful_remediations / len(items) if items else 0
        }

    async def _remediate_by_type(self, debt_type: DebtType,
                                items: List[TechnicalDebtItem]) -> Dict[str, Any]:
        """Remediate items of a specific type."""

        print(f"   ðŸ”§ Remediating {len(items)} {debt_type.value} items...")

        success_count = 0
        failed_count = 0

        for item in items:
            try:
                success = await self._remediate_single_item(item)
                if success:
                    success_count += 1
                    self.remediation_log.append(f"âœ… Fixed: {item.description}")
                else:
                    failed_count += 1
                    self.remediation_log.append(f"âŒ Failed: {item.description}")
            except Exception as e:
                failed_count += 1
                self.remediation_log.append(f"âŒ Error: {item.description} - {e}")

        return {'success': success_count, 'failed': failed_count}

    async def _remediate_single_item(self, item: TechnicalDebtItem) -> bool:
        """Remediate a single technical debt item."""

        try:
            if item.type == DebtType.CODE_COMPLEXITY:
                return await self._fix_code_complexity(item)
            elif item.type == DebtType.NAMING_CONSISTENCY:
                return await self._fix_naming_consistency(item)
            elif item.type == DebtType.DOCUMENTATION_DRIFT:
                return await self._fix_documentation(item)
            elif item.type == DebtType.SECURITY_ISSUES:
                return await self._fix_security_issue(item)
            else:
                # For other types, just log the recommendation
                print(f"      ðŸ’¡ Recommendation: {item.remediation_suggestion}")
                return True

        except Exception as e:
            print(f"      âŒ Error fixing {item.description}: {e}")
            return False

    async def _fix_code_complexity(self, item: TechnicalDebtItem) -> bool:
        """Fix code complexity issues."""
        if "Line too long" in item.description and item.line_number:
            try:
                file_path = Path(item.file_path)
                with open(file_path, 'r') as f:
                    lines = f.readlines()

                if item.line_number <= len(lines):
                    # Simple fix: break long line
                    long_line = lines[item.line_number - 1]
                    if len(long_line.strip()) > 120:
                        # Break at a reasonable point
                        break_point = long_line.rfind(',', 0, 100)
                        if break_point > 0:
                            lines[item.line_number - 1] = long_line[:break_point + 1] + '\n'
                            lines.insert(item.line_number, ' ' * 8 + long_line[break_point + 1:])

                            with open(file_path, 'w') as f:
                                f.writelines(lines)

                            print(f"      âœ… Fixed long line in {file_path.name}:{item.line_number}")
                            return True
            except Exception as e:
                print(f"      âš ï¸ Could not fix complexity issue: {e}")

        return False

    async def _log_recommendation(self, item: TechnicalDebtItem, prefix: str = "ðŸ’¡") -> bool:
        """Log a remediation recommendation (common handler for demo fixes)."""
        print(f"      {prefix} {item.remediation_suggestion}")
        return True

    async def _fix_naming_consistency(self, item: TechnicalDebtItem) -> bool:
        """Fix naming consistency issues."""
        return await self._log_recommendation(item)

    async def _fix_documentation(self, item: TechnicalDebtItem) -> bool:
        """Fix documentation issues."""
        return await self._log_recommendation(item)

    async def _fix_security_issue(self, item: TechnicalDebtItem) -> bool:
        """Fix security issues."""
        return await self._log_recommendation(item, "ðŸš¨ CRITICAL:")


class TechnicalDebtMonitor:
    """Continuous monitoring to prevent new technical debt."""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.baseline_assessment = None

    async def start_continuous_monitoring(self):
        """Start background monitoring for new technical debt."""
        print(f"ðŸ”„ Starting continuous technical debt monitoring...")

        # Create baseline
        scanner = TechnicalDebtScanner(str(self.project_root))
        self.baseline_assessment = await scanner.scan_all_issues()

        print(f"   ðŸ“Š Baseline: {self.baseline_assessment.total_debt_items} debt items")

        # In a real implementation, this would run continuously
        # For demo, just show the concept
        print(f"   ðŸ”„ Monitoring enabled - will alert on new debt accumulation")

        return self.baseline_assessment


# Main System Orchestrator
class TechnicalDebtOrchestrator:
    """Orchestrates the complete technical debt remediation process."""

    def __init__(self, project_root: str):
        self.project_root = project_root
        self.scanner = TechnicalDebtScanner(project_root)
        self.prioritizer = TechnicalDebatePrioritizer()
        self.remediator = TechnicalDebtRemediator(project_root)
        self.monitor = TechnicalDebtMonitor(project_root)

    async def execute_remediation_workflow(self, available_hours: int = 40) -> Dict[str, Any]:
        """Execute the complete technical debt remediation workflow."""

        print("ðŸš€ Starting Technical Debt Remediation Workflow")
        print("=" * 60)

        # Phase 1: Assessment
        print("\nðŸ“Š PHASE 1: Technical Debt Assessment")
        assessment = await self.scanner.scan_all_issues()

        # Display assessment results
        print(f"\nðŸ“ˆ Assessment Results:")
        print(f"   Total debt items: {assessment.total_debt_items}")
        print(f"   Estimated remediation time: {assessment.estimated_remediation_time} hours")
        print(f"   Priority items: {len(assessment.priority_items)}")

        print(f"\nðŸ“Š Debt by Type:")
        for debt_type, count in assessment.debt_by_type.items():
            print(f"   {debt_type.value}: {count}")

        print(f"\nðŸ“Š Debt by Severity:")
        for severity, count in assessment.debt_by_severity.items():
            print(f"   {severity.value}: {count}")

        # Phase 2: AI-Powered Prioritization
        print(f"\nðŸ¤– PHASE 2: AI-Powered Prioritization")
        prioritized_items = await self.prioritizer.prioritize_debt_items(
            assessment.priority_items, available_hours
        )

        print(f"\nðŸ“‹ Prioritized Remediation Plan:")
        total_effort = 0
        for i, item in enumerate(prioritized_items[:10], 1):
            print(f"   {i}. {item.severity.value.upper()} - {item.description}")
            print(f"      File: {Path(item.file_path).name}, Effort: {item.estimated_effort}h")
            total_effort += item.estimated_effort

        print(f"\n   Total planned effort: {total_effort} hours")

        # Phase 3: Parallel Remediation
        print(f"\nðŸ”§ PHASE 3: Parallel Remediation")
        remediation_results = await self.remediator.remediate_items(prioritized_items)

        print(f"\nðŸ“Š Remediation Results:")
        print(f"   Items processed: {remediation_results['total_items']}")
        print(f"   Successful: {remediation_results['successful']}")
        print(f"   Failed: {remediation_results['failed']}")
        print(f"   Success rate: {remediation_results['success_rate']:.1%}")

        # Phase 4: Continuous Monitoring
        print(f"\nðŸ”„ PHASE 4: Continuous Monitoring Setup")
        baseline = await self.monitor.start_continuous_monitoring()

        # Final summary
        print(f"\nðŸŽ¯ TECHNICAL DEBT REMEDIATION SUMMARY")
        print("=" * 60)
        print(f"âœ… Assessment completed: {assessment.total_debt_items} items identified")
        print(f"âœ… AI prioritization: {len(prioritized_items)} items selected")
        print(f"âœ… Remediation executed: {remediation_results['success_rate']:.1%} success rate")
        print(f"âœ… Continuous monitoring: Baseline established")

        return {
            'assessment': assessment,
            'prioritized_items': prioritized_items,
            'remediation_results': remediation_results,
            'monitoring_baseline': baseline
        }


# Demonstration
async def demonstrate_technical_debt_remediation():
    """Demonstrate the technical debt remediation system."""

    project_root = "."  # Current directory

    print("ðŸ”§ Technical Debt Remediation System Demonstration")
    print("=" * 80)
    print("This system uses parallel execution and AI debate to systematically")
    print("identify, prioritize, and resolve technical debt and codebase decay.\n")

    orchestrator = TechnicalDebtOrchestrator(project_root)

    results = await orchestrator.execute_remediation_workflow(available_hours=20)

    print(f"\nâœ… Technical Debt Remediation Workflow Completed!")

    return results


if __name__ == "__main__":
    asyncio.run(demonstrate_technical_debt_remediation())
